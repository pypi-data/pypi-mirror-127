# AUTOGENERATED! DO NOT EDIT! File to edit: source_nbs/05_preproc_decorator.ipynb (unless otherwise specified).

__all__ = ['has_key_startswith', 'convert_legacy_output', 'input_format_check', 'none_generator',
           'convert_data_to_features', 'convert_data_to_features_pyspark', 'check_if_le_created', 'preprocessing_fn']

# Cell
from typing import Any, Callable, Iterable, Generator

from loguru import logger
from fastcore.basics import chunked, listify, partial
from fastcore.parallel import num_cpus
from joblib import Parallel, delayed
import pandas as pd

from .bert_preprocessing.create_bert_features import \
    create_multimodal_bert_features
from .special_tokens import TRAIN, PREDICT
from .utils import (get_or_make_label_encoder,
                        load_transformer_tokenizer, set_is_pyspark)
from .params import Params


# Cell
def has_key_startswith(d: dict, prefix: str) -> bool:
    for k in d.keys():
        if k.startswith(prefix):
            return True
    return False


def convert_legacy_output(inp: Generator[tuple, None, None]) -> dict:
    """Convert legacy preproc output to dictionary

    Args:
        inp (Generator[tuple, None, None]): legacy format output

    Returns:
        dict: new format output

    Yields:
        Iterator[dict]
    """
    for record in inp:

        if isinstance(record, dict):
            yield record
        else:
            inputs, labels = record

            # need to do conversion
            if isinstance(inputs, dict) and not has_key_startswith(inputs, 'inputs_'):
                new_format_record = {'inputs_{}'.format(
                    k): v for k, v in inputs.items()}
            elif isinstance(inputs, dict):
                new_format_record = inputs
            else:
                new_format_record = {'inputs_text': inputs}

            if isinstance(labels, dict) and not has_key_startswith(labels, 'labels_'):
                new_format_record.update({
                    'labels_{}'.format(k): v for k, v in labels.items()
                })
            elif isinstance(labels, dict):
                new_format_record.update(labels)
            else:
                new_format_record['labels'] = labels
            yield new_format_record


def input_format_check(inp: dict, mode: str):
    if not isinstance(inp, dict):
        raise ValueError(
            "preproc outout content should be dict, got: {}".format(type(inp)))

    inputs_columns = [k for k in inp.keys() if k.startswith('inputs')]
    if not inputs_columns:
        raise ValueError(
            'inputs should has key with prefix "inputs", keys: {}'.format(inp.keys()))

    if mode != PREDICT:
        labels_columns = [k for k in inp.keys() if k.startswith('labels')]
        if not labels_columns:
            raise ValueError(
                'inputs should has key with prefix "labels", keys: {}'.format(inp.keys()))


# Cell

def none_generator(length: int = None) -> Generator[None, None, None]:
    if length is None:
        while True:
            yield None
    else:
        for _ in range(length):
            yield None


def convert_data_to_features(problem: str, data_iter: Iterable, params: Params, label_encoder: Any, tokenizer: Any, mode=TRAIN) -> Iterable[dict]:

    if mode != PREDICT:
        problem_type = params.problem_type[problem]

        # whether this problem is sequential labeling
        # for sequential labeling, targets needs to align with any
        # change of inputs
        is_seq = problem_type in ['seq_tag']
    else:
        problem_type = 'cls'
        is_seq = False

    part_fn = partial(create_multimodal_bert_features, problem=problem,
                      label_encoder=label_encoder,
                      params=params,
                      tokenizer=tokenizer,
                      mode=mode,
                      problem_type=problem_type,
                      is_seq=is_seq)
    preprocess_buffer = params.preprocess_buffer
    data_buffer_list = []
    num_cpus = params.num_cpus if params.num_cpus > 0 else num_cpus()
    # no easy fix for prediction in multiprocessing
    # phase is not shared between processes
    num_cpus = 1 if mode == PREDICT else num_cpus
    for data_buffer_list in chunked(data_iter, chunk_sz=preprocess_buffer):
        per_cpu_chunk = listify(chunked(data_buffer_list, n_chunks=num_cpus))
        res_gen = Parallel(num_cpus)(delayed(part_fn)(example_list=d_list)
                                     for d_list in per_cpu_chunk)
        for d_list in res_gen:
            for d in d_list:
                yield d


def convert_data_to_features_pyspark(
        problem: str, dataframe, params: Params, label_encoder: Any, tokenizer: Any, mode=TRAIN):

    # whether this problem is sequential labeling
    # for sequential labeling, targets needs to align with any
    # change of inputs
    from copy import deepcopy

    params_here = deepcopy(params)
    del params_here.read_data_fn

    params.num_cpus = 1

    dataframe = dataframe.mapPartitions(lambda x: convert_data_to_features(
        problem=problem, data_iter=x, params=params_here, tokenizer=tokenizer, label_encoder=label_encoder, mode=mode))

    return dataframe

def check_if_le_created(problem: str, params: Params):

    try:
        le_called: bool = params.get_problem_info(problem=problem, info_name='label_encoder_called')
        if not le_called:
            raise ValueError('If your preprocessing function returns'
                    ' a generator or pyspark RDD, you have to call `m3tl.utils.get_or_make_label_encoder` manually. \n'
                    'If you\'re implementing custom get or make label encoder fn, please specify '
                    'num_classes. Example: \n'
                    'params.set_problem_info(problem=problem, info_name="num_classes", info=100)'.format(problem))
    except KeyError:
        KeyError('If your preprocessing function returns'
                    ' a generator or pyspark RDD, you have to call `m3tl.utils.get_or_make_label_encoder` manually. \n'
                    'If you\'re implementing custom get or make label encoder fn, please specify '
                    'num_classes. Example: \n'
                    'params.set_problem_info(problem=problem, info_name="num_classes", info=100)'.format(problem))

# Cell
def preprocessing_fn(func: Callable):
    """Usually used as a decorator.

    The input and output signature of decorated function should be:
    func(params: m3tl.Params,
         mode: str) -> Union[Generator[X, y], Tuple[List[X], List[y]]]

    Where X can be:
    - Dicitionary of 'a' and 'b' texts: {'a': 'a test', 'b': 'b test'}
    - Text: 'a test'
    - Dicitionary of modalities: {'text': 'a test', 'image': np.array([1,2,3])}

    Where y can be:
    - Text or scalar: 'label_a'
    - List of text or scalar: ['label_a', 'label_a1'] (for seq2seq and seq_tag)

    This decorator will do the following things:
    - load tokenizer
    - call func, save as example_list
    - create label_encoder and count the number of rows of example_list
    - create bert features from example_list and write tfrecord

    Args:
        func (Callable): preprocessing function for problem
    """
    def wrapper(params, mode, get_data_num=False, write_tfrecord=True):
        problem = func.__name__

        tokenizer = load_transformer_tokenizer(
            params.transformer_tokenizer_name, params.transformer_tokenizer_loading)

        # proc func can return one of the following types:
        # - Generator
        # - Tuple[list] or list
        # - pyspark RDD
        example_list = func(params, mode)

        if isinstance(example_list, tuple) or isinstance(example_list, list):
            try:
                inputs_list, target_list = example_list
            except ValueError:
                inputs_list = example_list
                target_list = none_generator(len(inputs_list))

            if len(inputs_list) == 0:
                raise ValueError(
                    'problem {} preproc fn returns empty data'.format(problem))

            # ugly handling
            if isinstance(inputs_list, dict):
                inputs_list = pd.DataFrame(inputs_list).to_dict('records')

            example_list = zip(inputs_list, target_list)
            example_list = convert_legacy_output(example_list)

            if mode != PREDICT:
                label_encoder = get_or_make_label_encoder(
                    params, problem=problem, mode=mode, label_list=target_list)
            else:
                label_encoder = None

            return convert_data_to_features(
                problem=problem,
                data_iter=example_list,
                params=params,
                label_encoder=label_encoder,
                tokenizer=tokenizer,
                mode=mode
            )
        elif isinstance(example_list, Iterable):
            # trigger making label encoder
            try:
                next(example_list)
            except StopIteration:
                raise StopIteration(
                    'problem {} preproc fn returns empty data'.format(problem))

            example_list = func(params, mode)
            example_list = convert_legacy_output(example_list)

            # create label encoder
            if mode != PREDICT:
                check_if_le_created(problem, params)
                label_encoder = get_or_make_label_encoder(
                    params, problem=problem, mode=mode, label_list=[], overwrite=False)
            else:
                label_encoder = None

            return convert_data_to_features(
                problem=problem,
                data_iter=example_list,
                params=params,
                label_encoder=label_encoder,
                tokenizer=tokenizer,
                mode=mode
            )
        else:
            try:
                from pyspark import RDD
            except ImportError:
                raise ImportError(
                    "pyspark is not installed, in this case, preproc "
                    "function should return a generator, a tuple or a list.")

            if not isinstance(example_list, RDD):
                raise ValueError("preproc function should return a generator, a tuple, "
                "a list or a pyspark RDD, got {} from problem {}".format(
                    type(example_list), problem))

            set_is_pyspark(True)
            if params.pyspark_output_path is None:
                raise ValueError(
                    "preproc function of {} returns RDD but "
                    "params.pyspark_output_path is not set.".format(problem))

            if mode != PREDICT:
                check_if_le_created(problem, params)
                label_encoder = get_or_make_label_encoder(
                    params, problem=problem, mode=mode, label_list=[], overwrite=False)
            else:
                label_encoder = None

            return convert_data_to_features_pyspark(
                problem=problem,
                dataframe=example_list,
                params=params,
                label_encoder=label_encoder,
                tokenizer=tokenizer,
                mode=mode
            )
    return wrapper
